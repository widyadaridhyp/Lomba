{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/widyadaridhyp/Lomba/blob/main/prescriptive_analytics_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKdbsW6hipYs"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW8CDxFlaqyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8dc0fa-9906-40ac-a82b-58fb3dd61c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh-H7IZspUbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bdbe21-5290-498c-acbe-91ee455641d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lazypredict in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (3.3.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.7.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->lazypredict) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "R7whyI8H0_X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function():\n",
        "    %pip install nltk\n",
        "    import nltk\n",
        "    # Rest of your code that uses nltk\n",
        "\n",
        "# Other parts of your code"
      ],
      "metadata": {
        "id": "doqVCAk01Dtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "hO53pZSG35PS",
        "outputId": "8bbdf1f9-45e6-467f-f95a-59e9c1cc052a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-1d2184025e54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbleu_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_bleu\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mribes_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_ribes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mribes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeteor_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeteor_score\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmeteor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malignment_error_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/meteor_score.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetCorpusReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStemmerI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyCorpusLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \"\"\"\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaintext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mPlaintextCorpusReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpusReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0mReader\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcorpora\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mconsist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mplaintext\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mParagraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36mPlaintextCorpusReader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWordPunctTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msent_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLazyLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/english.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mpara_block_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_blankline_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPIvNh30G2EO"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "import spacy\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import io\n",
        "from plotly.offline import plot, iplot, init_notebook_mode\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew # for some statistics\n",
        "import warnings # to ignore warning\n",
        "from sklearn.preprocessing import RobustScaler, PowerTransformer, LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "import optuna\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LassoCV, RidgeCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLDzVsj5i71t"
      },
      "source": [
        "# **Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jRwwB9lIa7z"
      },
      "outputs": [],
      "source": [
        "target_df = pd.read_csv(\"train_label.csv\")\n",
        "train_df = pd.read_csv(\"train_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlLOveNcoZqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "148f683f-bed7-4797-b0fc-6428daf87522"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      facilities                        rating      location  \\\n",
              "0     RestaurantBARSwimmingPools  7.8 Very GoodFrom 10 reviews        Stokol   \n",
              "1           intrnetRestaurantgym        5.6 GoodFrom 4 reviews  Machlessvile   \n",
              "2           restaurantgympoolBar  7.2 Very GoodFrom 38 reviews    Wanderland   \n",
              "3                  BARRestaurant   7.3 Very GoodFrom 6 reviews    Uberlandia   \n",
              "4             InternetRestaurant  7.2 Very GoodFrom 30 reviews        Stokol   \n",
              "...                          ...                           ...           ...   \n",
              "3061                 barInternet                           NaN       Andeman   \n",
              "3062       restaurantBarInternet   8.1 ExcellentFrom 4 reviews    Uberlandia   \n",
              "3063  Barrestaurantswimmingpools  6.7 Very GoodFrom 10 reviews     Willsmian   \n",
              "3064                  Restaurant                           NaN     Hallerson   \n",
              "3065                     barPool  7.8 Very GoodFrom 26 reviews       Andeman   \n",
              "\n",
              "                Price  \n",
              "0     13,500avg/night  \n",
              "1     13,000avg/night  \n",
              "2     19,000avg/night  \n",
              "3      6,000avg/night  \n",
              "4     20,000avg/night  \n",
              "...               ...  \n",
              "3061  31,625avg/night  \n",
              "3062  30,500avg/night  \n",
              "3063  14,000avg/night  \n",
              "3064   8,500avg/night  \n",
              "3065  19,000avg/night  \n",
              "\n",
              "[3066 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cc88777-3479-4187-822b-4f813ca4ed95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>facilities</th>\n",
              "      <th>rating</th>\n",
              "      <th>location</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RestaurantBARSwimmingPools</td>\n",
              "      <td>7.8 Very GoodFrom 10 reviews</td>\n",
              "      <td>Stokol</td>\n",
              "      <td>13,500avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intrnetRestaurantgym</td>\n",
              "      <td>5.6 GoodFrom 4 reviews</td>\n",
              "      <td>Machlessvile</td>\n",
              "      <td>13,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>restaurantgympoolBar</td>\n",
              "      <td>7.2 Very GoodFrom 38 reviews</td>\n",
              "      <td>Wanderland</td>\n",
              "      <td>19,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BARRestaurant</td>\n",
              "      <td>7.3 Very GoodFrom 6 reviews</td>\n",
              "      <td>Uberlandia</td>\n",
              "      <td>6,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>InternetRestaurant</td>\n",
              "      <td>7.2 Very GoodFrom 30 reviews</td>\n",
              "      <td>Stokol</td>\n",
              "      <td>20,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3061</th>\n",
              "      <td>barInternet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Andeman</td>\n",
              "      <td>31,625avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3062</th>\n",
              "      <td>restaurantBarInternet</td>\n",
              "      <td>8.1 ExcellentFrom 4 reviews</td>\n",
              "      <td>Uberlandia</td>\n",
              "      <td>30,500avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3063</th>\n",
              "      <td>Barrestaurantswimmingpools</td>\n",
              "      <td>6.7 Very GoodFrom 10 reviews</td>\n",
              "      <td>Willsmian</td>\n",
              "      <td>14,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3064</th>\n",
              "      <td>Restaurant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hallerson</td>\n",
              "      <td>8,500avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3065</th>\n",
              "      <td>barPool</td>\n",
              "      <td>7.8 Very GoodFrom 26 reviews</td>\n",
              "      <td>Andeman</td>\n",
              "      <td>19,000avg/night</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3066 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc88777-3479-4187-822b-4f813ca4ed95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cc88777-3479-4187-822b-4f813ca4ed95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cc88777-3479-4187-822b-4f813ca4ed95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Add a key column to each dataset\n",
        "train_df['key'] = range(len(train_df))\n",
        "target_df['key'] = range(len(target_df))\n",
        "\n",
        "# Merge the datasets using the key column\n",
        "master_df = pd.merge(train_df, target_df, on='key')\n",
        "\n",
        "# Remove the key column\n",
        "master_df = master_df.drop('key', axis=1)\n",
        "\n",
        "master_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW1fN84DjgiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d3b21b-27e2-49d5-c65c-a0969dbb985c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size dataset: (3066, 4)\n"
          ]
        }
      ],
      "source": [
        "# Size Dataset\n",
        "print('Size dataset:', master_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nox4DQU9BH3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90920dc-87db-454b-a78b-856ebb6cbfc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3066 entries, 0 to 3065\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   facilities  2765 non-null   object\n",
            " 1   rating      2429 non-null   object\n",
            " 2   location    3066 non-null   object\n",
            " 3   Price       3066 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 119.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Data Overview\n",
        "master_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnSSdn-uJpyq"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjffoMbBm6Oj"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chKoZGmoxbBd"
      },
      "outputs": [],
      "source": [
        "# Change type obj to str\n",
        "master_df = master_df.astype({\"facilities\":\"str\",\"rating\":\"str\",\"Price\":\"str\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuhWTNUu3oss"
      },
      "source": [
        "Ubah tipe data untuk features 'facilities', 'rating', dan 'Price' dari object ke string supaya dapat digunakan modul nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "816tLWxgWn_u"
      },
      "source": [
        "###**Cleaning Feature 'rating'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkjZYJ0Dq80-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "39c684d0-a0a2-4474-cec9-352315397f62"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-4a61fc6d8d4a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def my_function()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "def my_function()\n",
        "# Download required resources from NLTK\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a function to extract rating, review, and total reviews\n",
        "def extract_info(text):\n",
        "    tokens = nltk.word_tokenize(str(text))  # Convert to string\n",
        "    rating = tokens[0]\n",
        "    review = tokens[1:-2]\n",
        "    total_reviews = tokens[-2] if len(tokens) >= 2 else None\n",
        "    return rating, review, total_reviews\n",
        "\n",
        "# Apply the function to the 'rating' column\n",
        "master_df[['rating', 'review', 'total reviews']] = master_df['rating'].apply(extract_info).apply(pd.Series)\n",
        "\n",
        "master_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn-8W2RA4GfW"
      },
      "source": [
        "Pisahkan data pada feature 'rating' menjadi 3 features baru yaitu 'rating' yang berisi rating pengunjung terhadap Kyozo hotel, 'review' yaitu keseluruhan review yang diberikan pengunjung, dan 'total reviews' yaitu banyaknya pengunjung yang melakukan review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx40uISoWi_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "a963665b-cfaf-485c-88aa-737efe6ac416"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'review'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9693c2e55f6a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace NaN, empty list, and None with NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total reviews'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'review'"
          ]
        }
      ],
      "source": [
        "# Replace NaN, empty list, and None with NaN\n",
        "master_df['rating'] = master_df['rating'].replace('nan', np.nan)\n",
        "master_df['review'] = master_df['review'].apply(lambda x: np.nan if len(x) == 0 else x)\n",
        "master_df['total reviews'] = master_df['total reviews'].apply(lambda x: np.nan if x is None else x)\n",
        "\n",
        "master_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3kI5n7W-Ag"
      },
      "source": [
        "###**Cleaning Feature 'facilities'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6Dm8QbrHYuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "74c7fdd5-403a-435c-bafc-767f2a36dd25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               facilities                        rating  \\\n",
              "0          restaurant, bar, swimming pool  7.8 Very GoodFrom 10 reviews   \n",
              "1               restaurant, gym, internet        5.6 GoodFrom 4 reviews   \n",
              "2     restaurant, bar, swimming pool, gym  7.2 Very GoodFrom 38 reviews   \n",
              "3                         restaurant, bar   7.3 Very GoodFrom 6 reviews   \n",
              "4                    restaurant, internet  7.2 Very GoodFrom 30 reviews   \n",
              "...                                   ...                           ...   \n",
              "3061                        bar, internet                           NaN   \n",
              "3062            restaurant, bar, internet   8.1 ExcellentFrom 4 reviews   \n",
              "3063       restaurant, bar, swimming pool  6.7 Very GoodFrom 10 reviews   \n",
              "3064                           restaurant                           NaN   \n",
              "3065                   bar, swimming pool  7.8 Very GoodFrom 26 reviews   \n",
              "\n",
              "          location            Price  \n",
              "0           Stokol  13,500avg/night  \n",
              "1     Machlessvile  13,000avg/night  \n",
              "2       Wanderland  19,000avg/night  \n",
              "3       Uberlandia   6,000avg/night  \n",
              "4           Stokol  20,000avg/night  \n",
              "...            ...              ...  \n",
              "3061       Andeman  31,625avg/night  \n",
              "3062    Uberlandia  30,500avg/night  \n",
              "3063     Willsmian  14,000avg/night  \n",
              "3064     Hallerson   8,500avg/night  \n",
              "3065       Andeman  19,000avg/night  \n",
              "\n",
              "[3066 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2007ca6-758d-4973-a16f-a62ce2fa31dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>facilities</th>\n",
              "      <th>rating</th>\n",
              "      <th>location</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>restaurant, bar, swimming pool</td>\n",
              "      <td>7.8 Very GoodFrom 10 reviews</td>\n",
              "      <td>Stokol</td>\n",
              "      <td>13,500avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>restaurant, gym, internet</td>\n",
              "      <td>5.6 GoodFrom 4 reviews</td>\n",
              "      <td>Machlessvile</td>\n",
              "      <td>13,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>restaurant, bar, swimming pool, gym</td>\n",
              "      <td>7.2 Very GoodFrom 38 reviews</td>\n",
              "      <td>Wanderland</td>\n",
              "      <td>19,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>restaurant, bar</td>\n",
              "      <td>7.3 Very GoodFrom 6 reviews</td>\n",
              "      <td>Uberlandia</td>\n",
              "      <td>6,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>restaurant, internet</td>\n",
              "      <td>7.2 Very GoodFrom 30 reviews</td>\n",
              "      <td>Stokol</td>\n",
              "      <td>20,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3061</th>\n",
              "      <td>bar, internet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Andeman</td>\n",
              "      <td>31,625avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3062</th>\n",
              "      <td>restaurant, bar, internet</td>\n",
              "      <td>8.1 ExcellentFrom 4 reviews</td>\n",
              "      <td>Uberlandia</td>\n",
              "      <td>30,500avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3063</th>\n",
              "      <td>restaurant, bar, swimming pool</td>\n",
              "      <td>6.7 Very GoodFrom 10 reviews</td>\n",
              "      <td>Willsmian</td>\n",
              "      <td>14,000avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3064</th>\n",
              "      <td>restaurant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hallerson</td>\n",
              "      <td>8,500avg/night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3065</th>\n",
              "      <td>bar, swimming pool</td>\n",
              "      <td>7.8 Very GoodFrom 26 reviews</td>\n",
              "      <td>Andeman</td>\n",
              "      <td>19,000avg/night</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3066 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2007ca6-758d-4973-a16f-a62ce2fa31dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2007ca6-758d-4973-a16f-a62ce2fa31dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2007ca6-758d-4973-a16f-a62ce2fa31dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Define the dictionary of facilities\n",
        "facilities_dict = {\n",
        "    'restaurant': ['restaurant', 'food'],\n",
        "    'bar': ['bar'],\n",
        "    'swimming pool': ['pool', 'swimming', 'pools'],\n",
        "    'gym': ['gym', 'fitness'],\n",
        "    'internet': ['internet', 'intrnet']\n",
        "}\n",
        "\n",
        "# Function to separate the text into facilities based on the dictionary\n",
        "def separate_facilities(text):\n",
        "    separated_text = []\n",
        "    for facility, keywords in facilities_dict.items():\n",
        "        if any(keyword in text.lower() for keyword in keywords):\n",
        "            separated_text.append(facility)\n",
        "    return ', '.join(separated_text)\n",
        "\n",
        "# Apply the separation function to the 'facilities' column\n",
        "master_df['facilities'] = master_df['facilities'].apply(separate_facilities)\n",
        "\n",
        "master_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy_bDaLB4_dP"
      },
      "source": [
        "Bersihkan data ada feature 'facilities' dengan memisahkan fasilitas-fasilitas yang ada pada Kyozo hotel menjadi data yang terurut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qHLkCgB69QL"
      },
      "outputs": [],
      "source": [
        "# Identify distinct values in the 'facilities' feature\n",
        "distinct_values = master_df['facilities'].str.split(', ').explode().unique()\n",
        "\n",
        "print(distinct_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdcfSSH2bZoV"
      },
      "outputs": [],
      "source": [
        "# Replace empty strings with NaN\n",
        "master_df['facilities'] = master_df['facilities'].replace('', np.nan)\n",
        "master_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAXVj-BV5Qkz"
      },
      "outputs": [],
      "source": [
        "# Feature engineering: 'have bar'\n",
        "master_df['have bar'] = master_df['facilities'].apply(lambda x: 2 if pd.isna(x) else (1 if 'bar' in x else 0))\n",
        "\n",
        "# Feature engineering: 'have restaurant'\n",
        "master_df['have restaurant'] = master_df['facilities'].apply(lambda x: 2 if pd.isna(x) else (1 if 'restaurant' in x else 0))\n",
        "\n",
        "# Feature engineering: 'have swimming pools'\n",
        "master_df['have swimming pool'] = master_df['facilities'].apply(lambda x: 2 if pd.isna(x) else (1 if 'swimming pool' in x else 0))\n",
        "\n",
        "# Feature engineering: 'have gym'\n",
        "master_df['have gym'] = master_df['facilities'].apply(lambda x: 2 if pd.isna(x) else (1 if 'gym' in x else 0))\n",
        "\n",
        "# Feature engineering: 'have internet'\n",
        "master_df['have internet'] = master_df['facilities'].apply(lambda x: 2 if pd.isna(x) else (1 if 'internet' in x else 0))\n",
        "\n",
        "master_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRz32TUvcyjV"
      },
      "source": [
        "###**Cleaning Feature 'Price'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGEMfyDy1mIh"
      },
      "outputs": [],
      "source": [
        "# Remove non-numeric characters from the 'Price' column\n",
        "master_df['Price'] = master_df['Price'].str.replace(',', '').str.extract('(\\d+)')\n",
        "\n",
        "# Convert the 'Price' column to integer type\n",
        "master_df['Price'] = master_df['Price'].astype(int)\n",
        "\n",
        "master_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44IK_SwnnKrk"
      },
      "source": [
        "# Handle Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2_ZnEFMoM6q"
      },
      "outputs": [],
      "source": [
        "master_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_LWgW9IWNVO"
      },
      "outputs": [],
      "source": [
        "# Missing Value\n",
        "print('The number of missing value on dataset:')\n",
        "master_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0GfdpY4xRef"
      },
      "outputs": [],
      "source": [
        "# Check percentage of missing values\n",
        "master_df.isna().sum()/len(master_df)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-eAeArYQH2S"
      },
      "outputs": [],
      "source": [
        "# Plot missing values\n",
        "sns.heatmap(master_df.isna(),yticklabels=False,cbar=False,cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pGFPRU9lrEc"
      },
      "source": [
        "Karena terdapat banyak missing value pada features 'facilities' dan 'rating', maka kita perlu menemukan hubungan antara missing value dengan variabel target 'price'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYHmDG6toFFq"
      },
      "source": [
        "# Mengganti Data Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFvoaw4-9lji"
      },
      "outputs": [],
      "source": [
        "# Nan: Diasumsikan lupa / tidak tahu fasilitas apa saja yang ada\n",
        "master_df.facilities.fillna('tidak tahu', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_KEKGYGve49"
      },
      "outputs": [],
      "source": [
        "# Boxplot the 'rating' column data\n",
        "# Replace 'From' with NaN\n",
        "master_df['rating'] = master_df['rating'].replace('From', pd.NA)\n",
        "\n",
        "# Drop rows with NaN values in the 'rating' column\n",
        "df_rating = master_df['rating'].dropna()\n",
        "\n",
        "# Convert the 'rating' column to float\n",
        "df_rating = df_rating.astype(float)\n",
        "\n",
        "sns.boxplot(df_rating)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqtXFgNAsScY"
      },
      "outputs": [],
      "source": [
        "# Replace missing values in the 'rating' feature with the mean of the available data\n",
        "master_df['rating'] = master_df['rating'].replace(np.nan, df_rating.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLaDS2N9wZgy"
      },
      "outputs": [],
      "source": [
        "# Boxplot the 'total_reviews' column data\n",
        "# Drop rows with NaN values in the 'rating' column\n",
        "df_totalreviews = master_df['total reviews'].dropna()\n",
        "\n",
        "# Convert the 'total_reviews' column to int\n",
        "df_totalreviews = df_totalreviews.astype(int)\n",
        "\n",
        "sns.boxplot(df_totalreviews)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiDnGbyNwMfY"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean of the 'total reviews' column\n",
        "mean_total_reviews = df_totalreviews.mean()\n",
        "\n",
        "# Replace the missing values with the mean and apply ceiling\n",
        "master_df['total reviews'] = master_df['total reviews'].replace(np.nan, np.ceil(mean_total_reviews))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C40VNKB8tBlN"
      },
      "outputs": [],
      "source": [
        "# Nan: Diasumsikan masuk kategori 'Very Good' beradasrkan mean yang telah diperoleh\n",
        "master_df.review.fillna(\"['Very', 'GoodFrom']\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC6XBTuUZofW"
      },
      "outputs": [],
      "source": [
        "# Plot missing values\n",
        "sns.heatmap(master_df.isna(),yticklabels=False,cbar=False,cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQlSNjADocmD"
      },
      "source": [
        "Berdasarkan heatmap diatas data sudah bersih dari missing values karena missing values sudah berhasil diubah berdasarkan asumsi dan modus data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnDe8-4_pLD9"
      },
      "source": [
        "# Labeling Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-xv_8ut51fw"
      },
      "outputs": [],
      "source": [
        "# Convert all elements in 'review' column to strings\n",
        "master_df['review'] = master_df['review'].astype(str)\n",
        "\n",
        "# Identify distinct values in the 'review' feature\n",
        "distinct_values_review = master_df['review'].unique()\n",
        "\n",
        "print(distinct_values_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKEp4Oa_-gr2"
      },
      "outputs": [],
      "source": [
        "# Identify distinct values in the 'location' feature\n",
        "distinct_values_loc = master_df['location'].unique()\n",
        "\n",
        "print(distinct_values_loc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7S-a5k2Z0KB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'review' column using LabelEncoder\n",
        "le.fit(master_df['review'].drop_duplicates())\n",
        "master_df['review'] = le.transform(master_df['review'])\n",
        "\n",
        "# Fit and transform the 'location' column using LabelEncoder\n",
        "le.fit(master_df['location'].drop_duplicates())\n",
        "master_df['location'] = le.transform(master_df['location'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPHHyyBy4DAp"
      },
      "outputs": [],
      "source": [
        "master_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6H17d_y4sqV"
      },
      "source": [
        "Labeling feature 'review'\n",
        "\n",
        "*   0 - Excellent\n",
        "*   1 - Fair\n",
        "*   2 - God\n",
        "*   3 - Very Good\n",
        "\n",
        "Labeling feature 'location'\n",
        "\n",
        "*   0 - Andeman\n",
        "*   1 - Hallerson\n",
        "*   2 - Machlessvile\n",
        "*   3 - Stokol\n",
        "*   4 - Uberlandia\n",
        "*   5 - Ubisville\n",
        "*   6 - Wanderland\n",
        "*   7 - Willsmian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4UpTVl4tVWN"
      },
      "outputs": [],
      "source": [
        "master_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWBLn0M9tTI8"
      },
      "outputs": [],
      "source": [
        "# Change type data\n",
        "master_df = master_df.astype({\"rating\":\"float\",\"total reviews\":\"int\"})\n",
        "# Drop irelevant feature\n",
        "master_df.drop(['facilities'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWjqTZ5rqUAu"
      },
      "source": [
        "# Lazy Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BWYIoqjywc5"
      },
      "source": [
        "Lazy Predict merupakan library Python yang menyediakan cara sederhana dan efisien untuk membuat prediksi. Lazy Predict adalah tools yang dapat memperlihatkan akurasi dari berbagai model untuk mempermudah proyek pemodelan prediktif."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7lWIX9c7RF7"
      },
      "outputs": [],
      "source": [
        "X = master_df[['rating', 'location', 'review', 'total reviews',\n",
        "       'have bar', 'have restaurant', 'have swimming pool', 'have gym',\n",
        "       'have internet']]\n",
        "y = master_df['Price']\n",
        "X = X.astype(np.float32)\n",
        "offset = int(X.shape[0] * 0.9)\n",
        "X_train, y_train = X[:offset], y[:offset]\n",
        "X_test, y_test = X[offset:], y[offset:]\n",
        "reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\n",
        "models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yaJdX5GJuw_"
      },
      "source": [
        "# **Exploratory Data Analysis**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rsav1AVCLjq"
      },
      "outputs": [],
      "source": [
        "# Change type data\n",
        "eda_df = master_df.astype({\"rating\":\"float\",\"location\":\"object\",\"review\":\"object\",\"total reviews\":\"int\",\"have bar\":\"object\",\n",
        "                              \"have restaurant\":\"object\",\"have swimming pool\":\"object\",\"have gym\":\"object\",\"have internet\":\"object\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prgRbhLYjtBo"
      },
      "outputs": [],
      "source": [
        "# Unique Columns\n",
        "eda_df.select_dtypes(include='object').nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b2bzbAGAnC8"
      },
      "source": [
        "Features di atas memiliki tipe data object dengan yang memiliki kategori dengan jumlah masing-masing dapat dilihat diatas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFzWHiO7QXt4"
      },
      "outputs": [],
      "source": [
        "# Check duplicate values\n",
        "eda_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trA8QTFpAh8k"
      },
      "source": [
        "Terdapat 436 data yang duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56ZoH24rd_9v"
      },
      "outputs": [],
      "source": [
        "# Uji korelasi atribut\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "corr = master_df.corr()\n",
        "hm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\", fmt='.2f', linewidths=.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzbd7fMyYUR"
      },
      "source": [
        "Berdasarkan korelasi matriks, bisa didapatkan bahwa :\n",
        "\n",
        "\n",
        "1.   Dengan nilai koefisien korelasi 0.6, terdapat korelasi yang kuat antara rekomendasi dokter pada vaksin H1N1 dan rekomendasi dokter pada vaksin flu seasonal.\n",
        "2.   Dengan nilai koefisien korelasi 0.56, terdapat korelasi sedang antara opini responden terhadap resiko vaksin H1N1 dan opini responden terhadap resiko vaksin flu seasonal.\n",
        "3.   Dengan nilai koefisien korelasi 0.48, terdapat korelasi sedang antara opini responden terhadap keefektifan vaksin H1N1 dan opini responden terhadap keefektifan vaksin flu seasonal.\n",
        "4.   Terdapat korelasi antara sudahkah responden mendapatkan vaksinasi H1N1 dengan rekomendasi dokter pada vaksin H1N1, opini responden terhadap keefektifan vaksin H1N1, opini responden terhadap resiko flu H1N1, dan sudahkan responden mendapatkan vaksinasi seasonal flu.\n",
        "5.   Terdapat korelasi antara sudahkah responden mendapatkan vaksinasi flu seasonal dengan rekomendasi dokter pada vaksin seasonal, opini responden terhadap keefektifan vaksin flu seasonal, opini responden terhadap resiko flu seasonal, kelompok usia, dan sudahkan responden mendapatkan vaksinasi H1N1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYGQhhCHjJOj"
      },
      "outputs": [],
      "source": [
        "# Membuat grafik rata-rata harga hotel dengan total reviews dan review\n",
        "fig = px.scatter(eda_df, x='total reviews', y='Price', color='review', size='Price',\n",
        "                 title=\"Hotel Price increase with Total Reviews among Review\",\n",
        "                 color_discrete_sequence=['#B14B51','#B7A294'],height=600)\n",
        "fig.update_layout(legend=dict(title='',orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "                  font_color=\"#303030\", xaxis=dict(title='Total Reviews',showgrid=False),\n",
        "                  yaxis=dict(title='Hotel Price, $',showgrid=False, zerolinecolor='#E5E5EA',\n",
        "                             showline=True, linecolor='#E5E5EA', linewidth=2))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG0Q2WUMNtQm"
      },
      "source": [
        "# Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhT5MmPTJwBo"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# get list of categorical variables\n",
        "categoric = ['location', 'review', 'have bar', 'have restaurant', 'have swimming pool', 'have gym', 'have internet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAtbc6DVXTwa"
      },
      "outputs": [],
      "source": [
        "# Menunjukan statistika deskriptif dari variabel kategorik di dataset\n",
        "# Filter the DataFrame to include only the categorical variables\n",
        "categorical_df = eda_df[categoric]\n",
        "\n",
        "# Use describe() on the categorical DataFrame\n",
        "categorical_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdtXKfTAXvWd"
      },
      "outputs": [],
      "source": [
        "# Menunjukan rata-rata harga hotel dari variabel kategorik\n",
        "for i in categoric:\n",
        "    obs=eda_df[i].value_counts()\n",
        "    avg_price=eda_df.groupby(i)[\"Price\"].mean()\n",
        "    display(pd.DataFrame({\"Number of Visitors\":obs, \"Average Price Hotel\":avg_price.map('${:,.2f}'.format)})\\\n",
        "            .sort_values('Number of Visitors', ascending=False)\\\n",
        "            .style.set_caption(\"Variable: {}\".format(i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fT_aCqltX8q"
      },
      "outputs": [],
      "source": [
        "# create figure with subplots\n",
        "fig, axs = plt.subplots(nrows = 2, ncols = 4, figsize = (20,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create Pie Chart for each categorical variable\n",
        "for i, var in enumerate(categoric):\n",
        "  counts = eda_df[var].value_counts()\n",
        "  labels = counts.index.tolist()\n",
        "  values = counts.values.tolist()\n",
        "  axs[i].pie(values, labels=labels, autopct='%1.1f%%')\n",
        "  axs[i].set_title(var)\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0qkWww1u2TW"
      },
      "outputs": [],
      "source": [
        "# Visualize Categorical Data\n",
        "# Initialize subplot\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
        "x_position = 0\n",
        "y_position = 0\n",
        "\n",
        "for i in categoric:\n",
        "    if i == 'review':\n",
        "        continue  # Skip the 'review' variable\n",
        "    if y_position == 3:\n",
        "        y_position = 0\n",
        "        x_position += 1\n",
        "    df_plot = eda_df.groupby(['review', i]).size().reset_index().pivot(columns='review', index=i, values=0)\n",
        "    ax = df_plot.plot(kind='bar', stacked=True, ax=axes[x_position, y_position])\n",
        "    ax.set_title(i)\n",
        "    plt.xticks(rotation=90)\n",
        "    ax.legend(loc='upper right')\n",
        "    y_position += 1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3RTqs6atACh"
      },
      "outputs": [],
      "source": [
        "# create figure with subplots\n",
        "fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize = (20,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create histplot for each categorical variable\n",
        "cat = ['location', 'have bar', 'have restaurant', 'have swimming pool', 'have gym', 'have internet']\n",
        "for i, var in enumerate(cat):\n",
        "  sns.histplot(x = var, hue = 'review', data = eda_df, ax=axs[i], multiple = 'fill', kde = False)\n",
        "  axs[i].set_xticklabels(eda_df[var].unique(), rotation = 90)\n",
        "  axs[i].set_xlabel(var)\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt6eY-sdhjgO"
      },
      "outputs": [],
      "source": [
        "# Membuat grafik distribusi harga hotel dengan review\n",
        "fig=px.histogram(eda_df, x='Price', color='review', opacity=0.7, barmode='overlay',\n",
        "                 histnorm='probability density', marginal='box',\n",
        "                 title=\"Distribution of Hotel Price by Review Category\",\n",
        "                 color_discrete_sequence=['#B14B51','#B7A294'])\n",
        "fig.update_layout(font_color=\"#303030\", xaxis_title='Hotel Price, $',\n",
        "                  yaxis=dict(title='Probability Density', gridcolor='#EAEAEA', zerolinecolor='#EAEAEA'),\n",
        "                  legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1, title=\"\"))\n",
        "fig.update_xaxes(showgrid=False, zerolinecolor='#EAEAEA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RqJg6pciml9"
      },
      "outputs": [],
      "source": [
        "# Membuat grafik harga hotel dengan lokasi dan review\n",
        "plot_df = eda_df.groupby(['location','review'])['Price'].mean()\n",
        "plot_df = plot_df.rename('Price').reset_index()\n",
        "fig = px.bar(plot_df, x='location', y='Price', color='review', height=800,\n",
        "             title=\"Average Hotel Price by Location and Review\",\n",
        "             #color_discrete_map={'0': '#BFC5DA','1': '#5D6A92', '2': '#808080', '3': '#800080'},\n",
        "             facet_row='review', text='Price', opacity=0.85, barmode='group')\n",
        "fig.update_traces(texttemplate='$%{text:,.0f}', textposition='outside',\n",
        "                  marker_line=dict(width=1, color='#303030'))\n",
        "fig.layout.yaxis2.update(matches=None)\n",
        "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
        "fig.update_xaxes(title=\"location\", row=1)\n",
        "fig.update_yaxes(title=\"Hotel Price, $\",  gridcolor='#E3E3E3', zeroline=True, zerolinewidth=2,\n",
        "                 showgrid=False, zerolinecolor='#E5E5EA',\n",
        "                 showline=True, linecolor='#E5E5EA', linewidth=2)\n",
        "fig.update_layout(font_color=\"#303030\", paper_bgcolor=\"white\", plot_bgcolor=\"white\",\n",
        "                  bargroupgap=0.05, bargap=0.2,\n",
        "                  legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1, title=\"\"))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmPq5C4k454d"
      },
      "outputs": [],
      "source": [
        "num_loc = master_df['location'].value_counts().sort_values(ascending=False)[0:20]\n",
        "num_loc.name = 'Count'\n",
        "num_loc.index.name = 'Location'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uMsdiJfVq_-"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=num_loc.index,y=num_loc)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxWhjYPkVAWi"
      },
      "outputs": [],
      "source": [
        "# draw a boxen of a categorical variable along with\n",
        "# how it effects the target variable which is in this case 'price'\n",
        "def draw_cate_vs_target(df, feature):\n",
        "    plt.grid(True)\n",
        "    ax = sns.boxenplot(data=df, x=feature, y='Price')\n",
        "    ax.set_title(f'{feature} vs price', fontdict={'fontsize': 18})\n",
        "\n",
        "# draw the countplot of a categorical variable\n",
        "def draw_cate_countplot(df, feature):\n",
        "    plt.grid(True)\n",
        "    ax = sns.countplot(x=df[feature])\n",
        "    ax.set_title(f'{feature}\\'s count', fontdict={'fontsize': 18})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFFVWq7jVHNd"
      },
      "outputs": [],
      "source": [
        "# draw a boxen plot of bar vs price\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.set_palette('Set2')\n",
        "plt.subplot(1, 2, 1)\n",
        "draw_cate_vs_target(master_df, categoric[2])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "draw_cate_countplot(master_df, categoric[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcayd92lVjIk"
      },
      "outputs": [],
      "source": [
        "# draw a boxen plot of restaurant vs price\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.set_palette('Set2')\n",
        "plt.subplot(1, 2, 1)\n",
        "draw_cate_vs_target(master_df, categoric[3])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "draw_cate_countplot(master_df, categoric[3])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fIkZ7GLVoZ8"
      },
      "outputs": [],
      "source": [
        "# draw a boxen plot of swimming pool vs price\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.set_palette('Set2')\n",
        "plt.subplot(1, 2, 1)\n",
        "draw_cate_vs_target(master_df, categoric[4])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "draw_cate_countplot(master_df, categoric[4])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe1rD2C5Vusp"
      },
      "outputs": [],
      "source": [
        "# draw a boxen plot of gym vs price\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.set_palette('Set2')\n",
        "plt.subplot(1, 2, 1)\n",
        "draw_cate_vs_target(master_df, categoric[5])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "draw_cate_countplot(master_df, categoric[5])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADbR9uI4Vzeb"
      },
      "outputs": [],
      "source": [
        "# draw a boxen plot of internet vs price\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.set_palette('Set2')\n",
        "plt.subplot(1, 2, 1)\n",
        "draw_cate_vs_target(master_df, categoric[6])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "draw_cate_countplot(master_df, categoric[6])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31UUqvbIPKtC"
      },
      "source": [
        "# Numerical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Iik_l_YXET0"
      },
      "outputs": [],
      "source": [
        "# Menunjukan statistika deskriptif dari variabel numerik di dataset\n",
        "master_df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbQVWteVPR3S"
      },
      "outputs": [],
      "source": [
        "# get list of numerical variables\n",
        "numeric = ['rating', 'total reviews', 'Price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k9fIeiHTgwO"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows = 3, ncols = 1, figsize = (10,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create boxplot for each numerical variable\n",
        "for i, var in enumerate(numeric):\n",
        "  sns.boxplot(x = var, data = master_df, ax=axs[i])\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5WErAk-Ub9v"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows = 3, ncols = 1, figsize = (10,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create boxplot for each numerical variable\n",
        "for i, var in enumerate(numeric):\n",
        "  sns.violinplot(x = var, data = master_df, ax=axs[i])\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjFcLSRUUyW-"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows = 3, ncols = 1, figsize = (10,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create boxplot for each numerical variable\n",
        "for i, var in enumerate(numeric):\n",
        "  sns.histplot(x = var, data = master_df, ax=axs[i])\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gANExPKvOGlN"
      },
      "outputs": [],
      "source": [
        "def bivariate_analysis(x):\n",
        "  plt.figure(figsize=(8,4))\n",
        "  ax = sns.regplot(x=x, y='Price',data=master_df)\n",
        "  ax.set_title(\"Price vs \"+x, fontsize=15)\n",
        "  ax.set_xlabel(x, fontsize=10)\n",
        "  ax.set_ylabel('Price', fontsize=10)\n",
        "  plt.locator_params(axis='x', nbins=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA1OOghpORqH"
      },
      "outputs": [],
      "source": [
        "for x in numeric:\n",
        "  if x == 'Price':\n",
        "    continue  # Skip the 'review' variable\n",
        "  bivariate_analysis(x)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mei4JSLAPLpI"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(master_df[numeric],diag_kind='kde')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTOePyJWA5CS"
      },
      "outputs": [],
      "source": [
        "eda_df.groupby('rating')['Price'].median().plot()\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Hotel Price vs Rating')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVYGjCQFqyPA"
      },
      "source": [
        "# **Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIllvYGapScH"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-uNwSXIPyXT"
      },
      "outputs": [],
      "source": [
        "# Drop the 'Price' column to prepare data for splitting\n",
        "X = master_df.drop(columns=['Price'])\n",
        "# Get the target variable\n",
        "y = master_df['Price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLnfy9D2QLMq"
      },
      "outputs": [],
      "source": [
        "# Split data into training, validation and test sets, ensuring the class distribution is maintained\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJFZPAYyxNg"
      },
      "source": [
        "# Hyperparameter Tuning using Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-jhcWdAywjq"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 48\n",
        "\n",
        "# 10-fold CV\n",
        "kfolds = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqAT4W_tzPcV"
      },
      "outputs": [],
      "source": [
        "def tune(objective):\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "\n",
        "    params = study.best_params\n",
        "    best_score = study.best_value\n",
        "    print(f\"Best score: {best_score} \\nOptimized parameters: {params}\")\n",
        "    return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHRvav7izZpo"
      },
      "source": [
        "# Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA4fdhvJzfMo"
      },
      "outputs": [],
      "source": [
        "def ridge_objective(trial):\n",
        "\n",
        "    _alpha = trial.suggest_float(\"alpha\", 0.1, 20)\n",
        "    ridge = Ridge(alpha=_alpha, random_state=RANDOM_SEED)\n",
        "    score = cross_val_score(ridge,X_train,y_train, cv=kfolds, scoring=\"neg_root_mean_squared_error\").mean()\n",
        "    return score\n",
        "\n",
        "ridge_params = tune(ridge_objective)\n",
        "\n",
        "# Best score: -0.13586760243668033\n",
        "# ridge_params = {'alpha': 19.997759851201025}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsGBrMYs0hP1"
      },
      "outputs": [],
      "source": [
        "ridge = Ridge(**ridge_params, random_state=RANDOM_SEED)\n",
        "ridge.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXsmgUdC2C9p"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "print('MAE:', mae_ridge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_juzzEQwLyDX"
      },
      "outputs": [],
      "source": [
        "g_ridge = pd.DataFrame({'actual': y_test, 'predicted': y_pred_ridge})\n",
        "g_ridge = g_ridge.sort_values(by=\"actual\").reset_index()\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(g_ridge['predicted'], label='Predicted')\n",
        "plt.plot(g_ridge['actual'], color='red', label='Actual')\n",
        "plt.legend(fontsize=15)\n",
        "plt.title('Ridge Model - Predicted vs Actual')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUo3oFfI2a80"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeqdQXMa2fBM"
      },
      "outputs": [],
      "source": [
        "def lasso_objective(trial):\n",
        "    _alpha = trial.suggest_float(\"alpha\", 0.0001, 1)\n",
        "    lasso = Lasso(alpha=_alpha, random_state=RANDOM_SEED)\n",
        "    score = cross_val_score(lasso,X_train,y_train, cv=kfolds, scoring=\"neg_root_mean_squared_error\").mean()\n",
        "    return score\n",
        "\n",
        "lasso_params = tune(lasso_objective)\n",
        "\n",
        "# Best score: -0.13319435700230317\n",
        "# lasso_params = {'alpha': 0.0006224224345371836}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qpo2w8R2_H-"
      },
      "outputs": [],
      "source": [
        "lasso = Lasso(**lasso_params, random_state=RANDOM_SEED)\n",
        "lasso.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFy6GH-23KdS"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "print('MAE:', mae_lasso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtNWnR6CC2xu"
      },
      "outputs": [],
      "source": [
        "g_lasso = pd.DataFrame({'actual': y_test, 'predicted': y_pred_lasso})\n",
        "g_lasso = g_lasso.sort_values(by=\"actual\").reset_index()\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(g_lasso['predicted'], label='Predicted')\n",
        "plt.plot(g_lasso['actual'], color='red', label='Actual')\n",
        "plt.legend(fontsize=15)\n",
        "plt.title('Lasso Model - Predicted vs Actual')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jowowhO33Pbq"
      },
      "source": [
        "# Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwExjLJ53TTK"
      },
      "outputs": [],
      "source": [
        "def gbr_objective(trial):\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 50, 2000)\n",
        "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
        "    _min_samp_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
        "    _min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 2, 20)\n",
        "    _max_features = trial.suggest_int(\"max_features\", 10, 50)\n",
        "\n",
        "    gbr = GradientBoostingRegressor(\n",
        "        n_estimators=_n_estimators,\n",
        "        learning_rate=_learning_rate,\n",
        "        max_depth=_max_depth,\n",
        "        max_features=_max_features,\n",
        "        min_samples_leaf=_min_samples_leaf,\n",
        "        min_samples_split=_min_samp_split,\n",
        "        random_state=RANDOM_SEED)\n",
        "\n",
        "    score = cross_val_score(gbr, X_train,y_train, cv=kfolds, scoring=\"neg_root_mean_squared_error\").mean()\n",
        "    return score\n",
        "\n",
        "gbr_params = tune(gbr_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgo0RYZE3k6P"
      },
      "outputs": [],
      "source": [
        "gbr = GradientBoostingRegressor(random_state=RANDOM_SEED, **gbr_params)\n",
        "gbr.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp73Bbfr3noP"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred_gbr = gbr.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
        "print('MAE:', mae_gbr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPVuJpS2DG5K"
      },
      "outputs": [],
      "source": [
        "g_gbr = pd.DataFrame({'actual': y_test, 'predicted': y_pred_gbr})\n",
        "g_gbr = g_gbr.sort_values(by=\"actual\").reset_index()\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(g_gbr['predicted'], label='Predicted')\n",
        "plt.plot(g_gbr['actual'], color='red', label='Actual')\n",
        "plt.legend(fontsize=15)\n",
        "plt.title('Gradient Boosting Model - Predicted vs Actual')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX_NV1yf4EPf"
      },
      "source": [
        "# XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM8_mnig4Ih-"
      },
      "outputs": [],
      "source": [
        "def xgb_objective(trial):\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 50, 2000)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
        "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1)\n",
        "    _gamma = trial.suggest_float(\"gamma\", 0.01, 1)\n",
        "    _min_child_weight = trial.suggest_float(\"min_child_weight\", 0.1, 10)\n",
        "    _subsample = trial.suggest_float('subsample', 0.01, 1)\n",
        "    _reg_alpha = trial.suggest_float('reg_alpha', 0.01, 10)\n",
        "    _reg_lambda = trial.suggest_float('reg_lambda', 0.01, 10)\n",
        "\n",
        "\n",
        "    xgbr = xgb.XGBRegressor(\n",
        "        n_estimators=_n_estimators,\n",
        "        max_depth=_max_depth,\n",
        "        learning_rate=_learning_rate,\n",
        "        gamma=_gamma,\n",
        "        min_child_weight=_min_child_weight,\n",
        "        subsample=_subsample,\n",
        "        reg_alpha=_reg_alpha,\n",
        "        reg_lambda=_reg_lambda,\n",
        "        random_state=RANDOM_SEED)\n",
        "\n",
        "    score = cross_val_score(xgbr, X_train,y_train, cv=kfolds, scoring=\"neg_root_mean_squared_error\").mean()\n",
        "    return score\n",
        "\n",
        "xgb_params = tune(xgb_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PI34EJt4UKH"
      },
      "outputs": [],
      "source": [
        "xgbr = xgb.XGBRegressor(random_state=RANDOM_SEED, **xgb_params)\n",
        "xgbr.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYZSM0aY4YQq"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred_xgbr = xgbr.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae_xgbr = mean_absolute_error(y_test, y_pred_xgbr)\n",
        "print('MAE:', mae_xgbr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG2Bah7dDac6"
      },
      "outputs": [],
      "source": [
        "g_xgbr = pd.DataFrame({'actual' : y_test,'predicted': y_pred_xgbr})\n",
        "g_xgbr = g_xgbr.sort_values(by=\"actual\").reset_index()\n",
        "plt.figure(figsize = (20,5))\n",
        "plt.plot(g_xgbr['predicted'])\n",
        "plt.plot(g_xgbr['actual'], color = 'red')\n",
        "plt.ylim(0,1000)\n",
        "plt.legend(['Predicted','Actual'],fontsize = 15)\n",
        "plt.title('XGBoost Model')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmSrPH_M4iHi"
      },
      "source": [
        "# LGBMRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAObphjU4lut"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "def lgb_objective(trial):\n",
        "    _num_leaves = trial.suggest_int(\"num_leaves\", 50, 100)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
        "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1)\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 50, 2000)\n",
        "    _min_child_weight = trial.suggest_float(\"min_child_weight\", 0.1, 10)\n",
        "    _reg_alpha = trial.suggest_float('reg_alpha', 0.01, 10)\n",
        "    _reg_lambda = trial.suggest_float('reg_lambda', 0.01, 10)\n",
        "    _subsample = trial.suggest_float('subsample', 0.01, 1)\n",
        "\n",
        "\n",
        "\n",
        "    lgbr = lgb.LGBMRegressor(objective='regression',\n",
        "                             num_leaves=_num_leaves,\n",
        "                             max_depth=_max_depth,\n",
        "                             learning_rate=_learning_rate,\n",
        "                             n_estimators=_n_estimators,\n",
        "                             min_child_weight=_min_child_weight,\n",
        "                             subsample=_subsample,\n",
        "                             reg_alpha=_reg_alpha,\n",
        "                             reg_lambda=_reg_lambda,\n",
        "                             random_state=RANDOM_SEED)\n",
        "\n",
        "\n",
        "    score = cross_val_score(lgbr, X_train,y_train, cv=kfolds, scoring=\"neg_root_mean_squared_error\").mean()\n",
        "    return score\n",
        "\n",
        "lgb_params = tune(lgb_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpUKKWI840Bu"
      },
      "outputs": [],
      "source": [
        "lgbr = lgb.LGBMRegressor(objective='regression', random_state=RANDOM_SEED, **lgb_params)\n",
        "lgbr.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXir5xUg47-g"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred_lgbr = lgbr.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae_lgbr = mean_absolute_error(y_test, y_pred_lgbr)\n",
        "print('MAE:', mae_lgbr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGtnSUeqDnVa"
      },
      "outputs": [],
      "source": [
        "g_lgbr = pd.DataFrame({'actual' : y_test,'predicted': y_pred_lgbr})\n",
        "g_lgbr = g_lgbr.sort_values(by=\"actual\").reset_index()\n",
        "plt.figure(figsize = (20,5))\n",
        "plt.plot(g_lgbr['predicted'])\n",
        "plt.plot(g_lgbr['actual'], color = 'red')\n",
        "plt.ylim(0,1000)\n",
        "plt.legend(['Predicted','Actual'],fontsize = 15)\n",
        "plt.title('LGBM Regressor Model')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXLVDYpuarlh"
      },
      "source": [
        "# LGBM Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiJIyXtMawDO"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6C22ObEbZb7"
      },
      "outputs": [],
      "source": [
        "def objective(trial,data=X,target=y):\n",
        "    param = {\n",
        "        'metric': 'mae',\n",
        "        'random_state': 48,\n",
        "        'n_estimators': 20000,\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n",
        "        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
        "        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n",
        "    }\n",
        "    model1 = LGBMRegressor(**param)\n",
        "\n",
        "    model1.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n",
        "\n",
        "    preds = model1.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "\n",
        "    return mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWBKRttOcF4i"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKZqSdPZc9U6"
      },
      "outputs": [],
      "source": [
        "# Define the best parameters obtained from Optuna\n",
        "best_params = study.best_params\n",
        "best_params['random_state'] = 48\n",
        "best_params['n_estimators'] = 20000\n",
        "best_params['metric'] = 'mae'\n",
        "\n",
        "# Initialize and fit the LGBMRegressor model with the best parameters\n",
        "model1 = LGBMRegressor(**best_params)\n",
        "model1.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE:', mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A24pGEysEGYY"
      },
      "outputs": [],
      "source": [
        "g_lgb = pd.DataFrame({'actual' : y_test,'predicted': y_pred})\n",
        "g_lgb = g_lgb.sort_values(by=\"actual\").reset_index()\n",
        "plt.figure(figsize = (20,5))\n",
        "plt.plot(g_lgb['predicted'])\n",
        "plt.plot(g_lgb['actual'], color = 'red')\n",
        "plt.ylim(0,1000)\n",
        "plt.legend(['Predicted','Actual'],fontsize = 15)\n",
        "plt.title('LGBM Regressor Model')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlQTDk10dPzT"
      },
      "outputs": [],
      "source": [
        "from optuna.integration import lightgbm as lgb\n",
        "lgb.plot_importance(model1, max_num_features=10, figsize=(10,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5_eQ_4SelVm"
      },
      "source": [
        "# XGBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5jbeyKaezgC"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b0AaNUQe0ef"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    param_grid = {\n",
        "        'tweedie_variance_power': trial.suggest_discrete_uniform('tweedie_variance_power', 1.0, 2.0, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 6, 10), # Extremely prone to overfitting!\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 400, 4000, 400), # Extremely prone to overfitting!\n",
        "        'eta': trial.suggest_float('eta', 0.007, 0.013), # Most important parameter.\n",
        "        'subsample': trial.suggest_discrete_uniform('subsample', 0.2, 0.9, 0.1),\n",
        "        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.2, 0.9, 0.1),\n",
        "        'colsample_bylevel': trial.suggest_discrete_uniform('colsample_bylevel', 0.2, 0.9, 0.1),\n",
        "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-4, 1e4), # I've had trouble with LB score until tuning this.\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 1e4), # L2 regularization\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 1e4), # L1 regularization\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n",
        "    }\n",
        "\n",
        "    reg = xgb.XGBModel(\n",
        "        # These parameters should help with trial speed.\n",
        "        objective='reg:tweedie',\n",
        "        tree_method='gpu_hist',\n",
        "        predictor='gpu_predictor',\n",
        "        n_jobs=4,\n",
        "        **param_grid\n",
        "    )\n",
        "\n",
        "    reg.fit(X_train, y_train,\n",
        "            eval_set=[(X_test, y_test)], eval_metric='mae',\n",
        "            verbose=False)\n",
        "\n",
        "    # Returns the best MAE for the trial.\n",
        "    # Readers may want to try returning a cross validation score here.\n",
        "    return mae(y_test, reg.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j2TojQBGN6E"
      },
      "outputs": [],
      "source": [
        "train_time = 1 * 60 * 60\n",
        "study = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='XGBRegressor')\n",
        "study.optimize(objective)\n",
        "print('Number of finished trials: ', len(study.trials))\n",
        "print('Best trial:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTCTgmpJGZH6"
      },
      "outputs": [],
      "source": [
        "# Fetch the best trial parameters and set some settings for the KFold predictions.\n",
        "xgb_params = study.best_trial\n",
        "xgb_params['objective'] = 'reg:tweedie'\n",
        "xgb_params['tree_method'] = 'gpu_hist'\n",
        "xgb_params['predictor'] = 'gpu_predictor'\n",
        "xgb_params['n_jobs'] = 4\n",
        "\n",
        "# Initialize and fit the XGBoostRegressor model with the best parameters\n",
        "model2 = xgb.XGBModel(**xgb_params)\n",
        "model2.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE:', mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c61NCVFTHmJi"
      },
      "outputs": [],
      "source": [
        "from optuna.integration import xgboost as xgb\n",
        "xgb.plot_importance(model2, max_num_features=10, figsize=(10,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOVsVtasUgqi"
      },
      "source": [
        "# Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46WPEurDUlSd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUsczhMKU3CW"
      },
      "outputs": [],
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation,\n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3b9TX4dVRCq"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('MAE: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    return accuracy\n",
        "\n",
        "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(X_train, y_train)\n",
        "base_accuracy = evaluate(base_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNbGM7XLVS12"
      },
      "outputs": [],
      "source": [
        "best_random = rf_random.best_estimator_\n",
        "random_accuracy = evaluate(best_random, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xithGj28nxA"
      },
      "source": [
        "# **Predict Data Test_Set_Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywbZgq5JTEFE"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"test_set_features.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll7ICYhGdfok"
      },
      "source": [
        "# Mengganti Data Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvHTsMg4dfol"
      },
      "outputs": [],
      "source": [
        "# Nan: Diasumsikan lupa / tidak tahu berarti ada kemungkinan memilihnya tidak berdasarkan hasil rekomendasi\n",
        "# sedemikian sehingga diasumsikan '0'\n",
        "test_df.doctor_recc_h1n1.fillna(0, inplace=True)\n",
        "test_df.doctor_recc_seasonal.fillna(0, inplace=True)\n",
        "test_df.chronic_med_condition.fillna(0,inplace=True)\n",
        "\n",
        "# Nan: Tidak tahu harus beropini apa\n",
        "test_df.opinion_h1n1_risk.fillna(3, inplace=True)\n",
        "test_df.opinion_h1n1_sick_from_vacc.fillna(3, inplace=True)\n",
        "test_df.opinion_seas_risk.fillna(3, inplace=True)\n",
        "test_df.opinion_h1n1_vacc_effective.fillna(3,inplace=True)\n",
        "test_df.opinion_seas_sick_from_vacc.fillna(3,inplace=True)\n",
        "test_df.opinion_seas_vacc_effective.fillna(3,inplace=True)\n",
        "\n",
        "# Nan: Tidak menjawab karena beranggapan variabel ini bersifat privasi\n",
        "test_df.income_poverty.fillna('privacy', inplace=True)\n",
        "test_df.marital_status.fillna('privacy', inplace=True)\n",
        "test_df.employment_industry.fillna('privacy',inplace=True)\n",
        "test_df.employment_occupation.fillna('privacy', inplace=True)\n",
        "test_df.employment_status.fillna('privacy', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhg7mqB_dfol"
      },
      "outputs": [],
      "source": [
        "# Missing values pada features yang tidak diasumsikan, diganti menjadi modus data\n",
        "test_df = test_df.fillna(test_df.mode().iloc[0])\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLIiTk6Kdfom"
      },
      "outputs": [],
      "source": [
        "test_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmj1tLkcdfom"
      },
      "source": [
        "Berdasarkan heatmap diatas data sudah bersih dari missing values karena missing values sudah berhasil diubah berdasarkan asumsi dan modus data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCsNGjETIQlp"
      },
      "source": [
        "# Labeling Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbNziULDdfon"
      },
      "outputs": [],
      "source": [
        "# Change type float to int\n",
        "test_df = test_df.astype({\"h1n1_concern\":\"int\",\"h1n1_knowledge\":\"int\",\"behavioral_antiviral_meds\":\"int\",\"behavioral_avoidance\":\"int\",\"behavioral_face_mask\":\"int\",\n",
        "                            \"behavioral_wash_hands\":\"int\",\"behavioral_large_gatherings\":\"int\",\"behavioral_outside_home\":\"int\",\"behavioral_touch_face\":\"int\",\n",
        "                            \"doctor_recc_h1n1\":\"int\",\"doctor_recc_seasonal\":\"int\",\"chronic_med_condition\":\"int\",\"child_under_6_months\":\"int\",\"opinion_h1n1_vacc_effective\":\"int\",\n",
        "                            \"opinion_h1n1_risk\":\"int\",\"opinion_h1n1_sick_from_vacc\":\"int\",\"opinion_seas_vacc_effective\":\"int\",\"opinion_seas_risk\":\"int\",\n",
        "                            \"opinion_seas_sick_from_vacc\":\"int\",\"household_adults\":\"int\",\"household_children\":\"int\"\n",
        "                            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r01kOLSiIQlp"
      },
      "outputs": [],
      "source": [
        "# Label Encoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Loop over each column in the DataFrame where dtype is 'object'\n",
        "for col in test_df.select_dtypes(include = ['object']).columns:\n",
        "  # Initialize a LabelEncoder object\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  # Fit the encoder to the unique values in the column\n",
        "  label_encoder.fit(test_df[col].unique())\n",
        "  # Transform the column using the encoder\n",
        "  test_df[col] = label_encoder.transform(test_df[col])\n",
        "  # Print the column name and the unique encoded values\n",
        "  print(f\"{col}: {test_df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A56vesuFdfon"
      },
      "outputs": [],
      "source": [
        "new_df = test_df[['h1n1_concern', 'h1n1_knowledge',\n",
        "       'behavioral_antiviral_meds', 'behavioral_avoidance',\n",
        "       'behavioral_face_mask', 'behavioral_wash_hands',\n",
        "       'behavioral_large_gatherings', 'behavioral_outside_home',\n",
        "       'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
        "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
        "       'health_insurance', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
        "       'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
        "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'age_group',\n",
        "       'education', 'race', 'sex', 'income_poverty', 'marital_status',\n",
        "       'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa',\n",
        "       'household_adults', 'household_children', 'employment_industry',\n",
        "       'employment_occupation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko790f5u8iYX"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the testing data\n",
        "y_new_pred = rfc.predict(new_df)\n",
        "\n",
        "# Create a DataFrame with the predicted labels\n",
        "h1n1_vaccine_pred = pd.DataFrame({'h1n1_vaccine': y_new_pred})\n",
        "h1n1_vaccine_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehe7kjz0FzcG"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the testing data\n",
        "y2_pred = rfc2.predict(new_df)\n",
        "\n",
        "# Create a DataFrame with the predicted labels\n",
        "seasonal_vaccine_pred = pd.DataFrame({'seasonal_vaccine': y2_pred})\n",
        "seasonal_vaccine_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-covsNghdfoo"
      },
      "outputs": [],
      "source": [
        "train_df.respondent_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdrOcSTMdfop"
      },
      "outputs": [],
      "source": [
        "submission_format = pd.DataFrame([])\n",
        "\n",
        "submission_format['respondent_id'] = test_df.respondent_id\n",
        "submission_format['h1n1_vaccine'] = h1n1_vaccine_pred\n",
        "submission_format['seasonal_vaccine'] = seasonal_vaccine_pred\n",
        "submission_format = submission_format.set_index('respondent_id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L93GPwYudfop"
      },
      "outputs": [],
      "source": [
        "submission_format.to_csv('submission_format.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNTY887BYkb7"
      },
      "source": [
        "# **Daftar Pustaka**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWWcgtPIYqYC"
      },
      "source": [
        "1.   https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\n",
        "2.   https://towardsdatascience.com/understanding-random-forest-58381e0602d2\n",
        "3.   https://lazypredict.readthedocs.io/en/latest/usage.html#classification\n",
        "4.   https://towardsdatascience.com/understanding-random-forest-58381e0602d2\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nKdbsW6hipYs",
        "CLDzVsj5i71t",
        "RjffoMbBm6Oj",
        "44IK_SwnnKrk",
        "UYHmDG6toFFq",
        "xnDe8-4_pLD9",
        "VWjqTZ5rqUAu",
        "AIllvYGapScH",
        "9xithGj28nxA",
        "ll7ICYhGdfok",
        "bCsNGjETIQlp"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}